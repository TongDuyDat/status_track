services:
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: track_status_worker
    restart: unless-stopped

    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: all
      REDIS_HOST: host.docker.internal
      REDIS_PORT: 6379
      REDIS_DB: 0
      REDIS_PASSWORD: ""
      PIPELINE_MODE: staged
      WORKER_BATCH_SIZE: 16
      BATCH_TIMEOUT: 0.05
      MAX_CONCURRENT_BATCHES: 10
      LOG_LEVEL: INFO
      RAM_THRESHOLD: 0.85
      GPU_THRESHOLD: 0.90
      MAX_QUEUE_SIZE: 1000
      TRUCK_MAX_BATCH: 32
      TEXT_MAX_BATCH: 16
      OCR_MAX_BATCH: 64
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    volumes:
      - ./track_model:/app/track_model:ro
      - ./text_detection:/app/text_detection:ro
      - ./text_recognition:/app/text_recognition:ro
      - ./results:/app/results
      - ./logs:/app/logs
      - ./trt_cache:/app/trt_cache
      - ./images:/app/images:ro
      - ./images_test:/app/images_test:ro
    
    command: python start_worker_optimized.py

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: track_status_api
    restart: unless-stopped
    environment:
      REDIS_HOST: host.docker.internal
      REDIS_PORT: 6379
      REDIS_DB: 0
      REDIS_PASSWORD: ""
      LOG_LEVEL: INFO
    env_file:
      - .env
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./images:/app/images
      - ./results:/app/results
      - ./logs:/app/logs
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

networks:
  default:
    driver: bridge